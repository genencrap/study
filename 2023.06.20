from JiYeop Kim 
[논문리뷰] High-Resolution Image Synthesis with Latent Diffusion Models (Stable Diffusion)
arXiv 2021. [Paper] [Github]
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer
Ludwig Maximilian University of Munich & IWR, Heidelberg University, Germany | Runway ML
20 Dec 2021

IntroductionPermalink
Diffusion model은 이미지 합성과 super-resolution 분야에서 굉장히 좋은 성능을 보였다. 하지만 데이터의 감지할 수 없는 세부 정보를 모델링하는 데 과도한 자원을 소비하는 경향이 있다. 
DDPM(논문리뷰)의 재가중된 목적 함수는 초기 노이즈 제거 단계에서 적게 샘플링하여 이 문제를 해결하고자 하지만 이러한 모델을 학습시키고 평가하려면 RGB 이미지의 고차원 공간에서 
반복적인 기울기 계산이 필요하기 때문에 여전히 계산적으로 까다롭다.
이러한 모델을 학습시키려면 방대한 컴퓨팅 리소스가 필요하며, 이미 학습된 모델을 평가하기 위해 동일한 모델 아키텍처를 여러 단계에 대해 순차적으로 실행하기 때문에 시간과 메모리가 많이 든다. 
강력한 diffusion model에 접근성을 높이고 동시에 상당한 리소스 사용을 줄이려면 학습 및 샘플링 모두에 대한 계산 복잡성을 줄여야 한다. 
따라서 diffusion model의 접근성을 높이기 위해서는 성능을 저하시키지 않으면서 계산 요구량을 줄이는 것이 핵심이다.



저자들의 접근 방식은 픽셀 공간에서 이미 학습된 diffusion model의 분석으로 시작한다. 위 그림은 학습된 모델의 rate-distortion trade-off를 보여준다. 
다른 likelihood 기반 모델과 마찬가지로 학습은 대략 두 단계로 나눌 수 있다.

Perceptual compression: high-frequency detail들을 제거하지만 의미(semantic)는 거의 학습하지 않는 단계
Semantic compression: 실제 생성 모델이 데이터의 의미론적(semantic) 구성과 개념적(conceptual) 구성을 학습하는 단계
따라서 저자들은 먼저 perceptual하게 동등하지만 계산적으로 더 적합한 space를 찾는 것을 목표로 하며 고해상도 이미지 합성을 위해 diffusion model을 학습시킨다.

먼저, 데이터 space와 perceptual하게 동일한 저차원 representational space로 보내는 autoencoder를 학습한다. 
중요한 것은 학습된 잠재 공간에서 diffusion model을 학습시키므로 이전 모델들과 달리 과도한 space 압축에 의존할 필요가 없다는 것이다.
또한 감소된 복잡성으로 인해 네트워크를 한 번만 통과하여 latent space에서 효율적인 이미지 생성이 가능하다. 이 모델을 LDM(Latent Diffusion Models)이라고 한다.

이 접근 방식의 주목할만한 장점은 범용 autoencoding 단계를 한 번만 학습하면 되므로 여러 diffusion model 학습에 재사용하거나 완전히 다른 task를 탐색할 수 있다는 것이다. 
이를 통해 다양한 image-to-image 및 text-to-image task를 위한 여러 diffusion model을 효율적으로 탐색할 수 있다. 
후자의 경우 트랜스포머를 diffusion model의 UNet backbone에 연결하고 임의의 유형의 토큰으로 조건을 주는 아키텍처를 설계한다.

MethodPermalink
고해상도 이미지 합성에 대한 diffusion model 학습의 계산 요구량을 낮추기 위해 diffusion model이 해당 손실 항을 적게 샘플링하여 perceptual하게 관련 없는 detail들을 무시할 수 있지만
여전히 픽셀 space에서 계산 비용이 많이 드므로 계산 시간과 컴퓨팅 리소스가 많이 필요하다. 저자들은 학습 단계에서 압축을 명시적으로 분리하여 이러한 단점을 피할 것을 제안한다.
이를 위해 이미지 공간과 perceptual하게 동일한 공간을 학습하지만 계산 복잡성을 크게 줄이는 autoencoding 모델을 활용한다.

이러한 접근은 여러 장점이 있다.

고차원 이미지 space를 남겨두어 저차원 space에서 샘플링이 수행되기 때문에 계산적으로 훨씬 더 효율적이다.
UNet 아키텍처에서 상속된 diffusion model의 inductive bias를 활용하여 공간 구조가 있는 데이터에 특히 효과적이다.
Latent space가 여러 생성 모델을 훈련하는 데 사용할 수 있고 downstream task (e.g., CLIP-guided synthesis)에도 활용 가능한 범용 압축 모델을 얻는다.

1. On Perceptual Compression TradeoffsPermalink
아래 표는 이 섹션에서 비교한 LDM에 사용된 first stage model의 hyper-parameter 및 재구성 성능을 보여준다.
//
아래 그래프는 ImageNet으로 클래스 조건부 모델을 200만 step 학습할 때 step에 대한 샘플 품질(FID, IS)을 보여준다.
(100 DDIM step으로 샘플링)
//
이를 통해 2가지를 확인할 수 있다.

작은 downsampling factor는 학습을 느리게 한다. (LDM-1, LDM-2)
지나치게 큰 f 값은 비교적 적은 step에서 샘플 품질의 정체를 유발한다. (LDM-32)
LDM-4부터 LDM-16까지는 효율성과 perceptual하게 충실한 결과 사이에서 적절한 균형을 유지한다.

아래 그래프는 CelebA-HQ와 ImageNet으로 학습한 LDM의 샘플링 속도와 FID를 비교한 결과이다. 
CelebA-HQ는 50만 step, ImageNet은 200만 step동안 학습되었으며 각 마커는 10, 20, 50, 100, 200 DDIM step으로 샘플링하였다.
//
이를 통해 LDM-4와 LDM-8의 성능이 제일 좋다는 것을 알 수 있다.


LimitationsPermalink
LDM은 픽셀 기반의 방식에 비해 계산 요구량을 크게 줄이지만 샘플링은 여전히 GAN보다 느리다. 또한 높은 정밀도가 필요할 때 LDM을 사용하는 것은 의문의 여지가 있다.
f=4 autoencoding model에서는 이미지 품질 손실이 매우 적지만, 픽셀 space에서 세밀한 정확도가 필요한 작업의 경우 재구성 기능이 병목될 수 있다. 
저자들은 super-resolution 모델이 이 점에서 이미 어느 정도 제한되어 있다고 생각한다.
